{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6549ba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Release_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Super Luigi U</td>\n",
       "      <td>WiiU</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Platform</td>\n",
       "      <td>E</td>\n",
       "      <td>1250000</td>\n",
       "      <td>620000</td>\n",
       "      <td>180000</td>\n",
       "      <td>180000</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>7.9</td>\n",
       "      <td>288</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tetris DS</td>\n",
       "      <td>DS</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>E</td>\n",
       "      <td>630000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1350000</td>\n",
       "      <td>80000</td>\n",
       "      <td>84</td>\n",
       "      <td>56</td>\n",
       "      <td>8.7</td>\n",
       "      <td>44</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classic NES Series: Super Mario Bros.</td>\n",
       "      <td>GBA</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Platform</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1390000</td>\n",
       "      <td>30000</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>8.6</td>\n",
       "      <td>44</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pikmin 2</td>\n",
       "      <td>GC</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>E</td>\n",
       "      <td>480000</td>\n",
       "      <td>130000</td>\n",
       "      <td>560000</td>\n",
       "      <td>30000</td>\n",
       "      <td>90</td>\n",
       "      <td>54</td>\n",
       "      <td>9.1</td>\n",
       "      <td>137</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mario vs. Donkey Kong</td>\n",
       "      <td>GBA</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>E</td>\n",
       "      <td>680000</td>\n",
       "      <td>250000</td>\n",
       "      <td>210000</td>\n",
       "      <td>20000</td>\n",
       "      <td>81</td>\n",
       "      <td>43</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Game_Name Platform Publisher Developer  \\\n",
       "0                      New Super Luigi U     WiiU  Nintendo  Nintendo   \n",
       "1                              Tetris DS       DS  Nintendo  Nintendo   \n",
       "2  Classic NES Series: Super Mario Bros.      GBA  Nintendo  Nintendo   \n",
       "3                               Pikmin 2       GC  Nintendo  Nintendo   \n",
       "4                  Mario vs. Donkey Kong      GBA  Nintendo  Nintendo   \n",
       "\n",
       "      Genre Rating  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
       "0  Platform      E   1250000    620000    180000       180000            77   \n",
       "1    Puzzle      E    630000     50000   1350000        80000            84   \n",
       "2  Platform      E         0         0   1390000        30000            84   \n",
       "3  Strategy      E    480000    130000    560000        30000            90   \n",
       "4    Puzzle      E    680000    250000    210000        20000            81   \n",
       "\n",
       "   Critic_Count  User_Score  User_Count  Release_Date  \n",
       "0            59         7.9         288          2013  \n",
       "1            56         8.7          44          2006  \n",
       "2            14         8.6          44          2004  \n",
       "3            54         9.1         137          2004  \n",
       "4            43         8.0          31          2004  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "db_username_read = open('db_username.txt')\n",
    "db_username = db_username_read.read()\n",
    "db_username_read.close()\n",
    "\n",
    "db_password_read = open('db_password.txt')\n",
    "db_password = db_password_read.read()\n",
    "db_password_read.close()\n",
    "\n",
    "db_host_read = open('db_host.txt')\n",
    "db_host = db_host_read.read()\n",
    "db_host_read.close()\n",
    "\n",
    "connection = cx_Oracle.connect(user=db_username, password=db_password, dsn=db_host)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Wyciągnięcie danych z bazy\n",
    "query = \"\"\"\n",
    "SELECT gs.game_name, p.platform_name, pub.publisher_name, d.developer_name, g.genre_name, r.rating_name, gs.na_sales, gs.eu_sales, gs.jp_sales, gs.other_sales, gs.critic_score, gs.critic_count, gs.user_score, gs.user_count, gs.release_date\n",
    "FROM game_sales gs\n",
    "JOIN platforms p ON gs.platform_id = p.platform_id\n",
    "JOIN publishers pub ON gs.publisher_id = pub.publisher_id\n",
    "JOIN developers d ON gs.developer_id = d.developer_id\n",
    "JOIN genres g ON gs.genre_id = g.genre_id\n",
    "JOIN ratings r ON gs.rating_id = r.rating_id\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "columns = ['Game_Name', 'Platform', 'Publisher', 'Developer', 'Genre', 'Rating', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count', 'Release_Date']\n",
    "data = cursor.fetchall()\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05c85018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumna: NA_Sales\n",
      "Test Shapiro-Wilka: ShapiroResult(statistic=0.32624709606170654, pvalue=0.0)\n",
      "Test Kołomogorowa – Smirnowa: KstestResult(statistic=0.9204395604395604, pvalue=0.0, statistic_location=10000, statistic_sign=-1)\n",
      "Test Lillieforsa: (0.34171641057249014, 0.0009999999999998899)\n",
      "\n",
      "Kolumna: EU_Sales\n",
      "Test Shapiro-Wilka: ShapiroResult(statistic=0.2929936647415161, pvalue=0.0)\n",
      "Test Kołomogorowa – Smirnowa: KstestResult(statistic=0.8644688644688645, pvalue=0.0, statistic_location=10000, statistic_sign=-1)\n",
      "Test Lillieforsa: (0.3656158046873703, 0.0009999999999998899)\n",
      "\n",
      "Kolumna: Critic_Score\n",
      "Test Shapiro-Wilka: ShapiroResult(statistic=0.9636805653572083, pvalue=2.761719651146815e-38)\n",
      "Test Kołomogorowa – Smirnowa: KstestResult(statistic=1.0, pvalue=0.0, statistic_location=13, statistic_sign=-1)\n",
      "Test Lillieforsa: (0.0786937887537918, 0.0009999999999998899)\n",
      "\n",
      "Kolumna: Critic_Count\n",
      "Test Shapiro-Wilka: ShapiroResult(statistic=0.9195757508277893, pvalue=0.0)\n",
      "Test Kołomogorowa – Smirnowa: KstestResult(statistic=0.9998218086116467, pvalue=0.0, statistic_location=4, statistic_sign=-1)\n",
      "Test Lillieforsa: (0.10335873472225349, 0.0009999999999998899)\n",
      "\n",
      "Pvalue wszystkich zmiennych jest < 0.05, więc odrzucamy hipotezę zerową więc ich rozkład nie jest normalny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\scipy\\stats\\_morestats.py:1816: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "columns = ['NA_Sales', 'EU_Sales', 'Critic_Score', 'Critic_Count']\n",
    "\n",
    "# H0 : Zmienne 'NA_Sales', 'EU_Sales', 'Critic_Score', 'Critic_Count' mają rozkład normalny.\n",
    "# H1 : Zmienne 'NA_Sales', 'EU_Sales', 'Critic_Score', 'Critic_Count' nie mają rozkładu normalnego.\n",
    "\n",
    "for column in columns:\n",
    "    shapiro_results = stats.shapiro(df[column])\n",
    "\n",
    "    ks_results = stats.kstest(df[column], 'norm')\n",
    "\n",
    "    lilliefors_results = lilliefors(df[column])\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Kolumna: {column}')\n",
    "    print('Test Shapiro-Wilka:', shapiro_results)\n",
    "    print('Test Kołomogorowa – Smirnowa:', ks_results)\n",
    "    print('Test Lillieforsa:', lilliefors_results)\n",
    "    print()\n",
    "    \n",
    "print(\"Pvalue wszystkich zmiennych jest < 0.05, więc odrzucamy hipotezę zerową więc ich rozkład nie jest normalny.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "911dcd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ANOVA: Statystyka = 414.4237319347391, p-wartość = 2.721379311330356e-263\n",
      "Pvalue jest < 0.05 odrzucamy hipotezę zerową, więc istnieje istotna różnica między średnią sprzedażą w różnych regionach\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# H0 : Nie ma istotnej różnicy między średnią sprzedażą w różnych regionach.\n",
    "# H1 : Różnicy między średnią sprzedażą w różnych regionach jest istotna.\n",
    "\n",
    "f_stat, f_pvalue = f_oneway(na_sales, eu_sales, jp_sales, other_sales)\n",
    "print(f\"Test ANOVA: Statystyka = {f_stat}, p-wartość = {f_pvalue}\")\n",
    "print(\"Pvalue jest < 0.05 odrzucamy hipotezę zerową, więc istnieje istotna różnica między średnią sprzedażą w różnych regionach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b5ce633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Levene'a: Statystyka = 298.93774732362385, p-value = 5.780531871654576e-191\n",
      "P-value jest < 0.05 odrzucamy hipotezę zerową, więc o wariancje nie są równe.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# H0 : Wariancje liczb sprzedanych kopii gier między regionami są równe.\n",
    "# H1 : Wariancje liczb sprzedanych kopii gier między regionami nie są równe.\n",
    "\n",
    "levene_stat, levene_pvalue = levene(na_sales, eu_sales, jp_sales, other_sales)\n",
    "print(f\"Test Levene'a: Statystyka = {levene_stat}, p-value = {levene_pvalue}\")\n",
    "print(\"P-value jest < 0.05 odrzucamy hipotezę zerową, więc o wariancje nie są równe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3853ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Sales'] = na_sales + eu_sales + jp_sales + other_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "920a3503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korelacja Pearsona: 0.46860734911026697, p-value: 0.0\n",
      "P-value jest < 0.05 odrzucamy hipotezę zerową, więc istnieje zależność między liczbą sprzedanych kopii w Ameryce Północnej, a w Japonii\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# H0: Nie istnieje zależność między liczbą sprzedanych kopii w Ameryce Północnej, a w Japonii.\n",
    "# H1: Istnieje zależność między liczbą sprzedanych kopii w Ameryce Północnej, a w Japonii.\n",
    "\n",
    "correlation_stat, p_value = pearsonr(na_sales, jp_sales)\n",
    "print(f\"Korelacja Pearsona: {correlation_stat}, p-value: {p_value}\")\n",
    "print(\"P-value jest < 0.05 odrzucamy hipotezę zerową, więc istnieje zależność między liczbą sprzedanych kopii w Ameryce Północnej, a w Japonii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7f2e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korelacja Pearsona: 0.23755507999330613, p-value: 3.517599461271442e-88\n",
      "P-value jest < 0.05 odrzucamy hipotezę zerową, więc istnieje zależność między oceną krytyków, a ogólną sprzedażą\n"
     ]
    }
   ],
   "source": [
    "# H0: Nie istnieje zależność między oceną krytyków, ogólną sprzedażą.\n",
    "# H1: Istnieje zależność między oceną krytyków, ogólną sprzedażą.\n",
    "\n",
    "correlation_stat, p_value = pearsonr(df['Critic_Score'], df['Total_Sales'])\n",
    "print(f\"Korelacja Pearsona: {correlation_stat}, p-value: {p_value}\")\n",
    "print(\"P-value jest < 0.05 odrzucamy hipotezę zerową, więc istnieje zależność między oceną krytyków, a ogólną sprzedażą\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74bfb025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-stat = -1.4432463986984838, p-value= 0.9252790630064545\n",
      "P-value jest > 0.05 nie odrzucamy hipotezy zerowej, więc że nie mamy wystarczających dowodów, aby stwierdzić że średnia sprzedaż była większa w 2015 niż w 2010 roku.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Czy średnia sprzedaż gier była większa w 2015 niż 2010?\n",
    "\n",
    "sales_2010 = df[df['Release_Date'] == 2010]['Total_Sales']\n",
    "sales_2015 = df[df['Release_Date'] == 2015]['Total_Sales']\n",
    "\n",
    "# przeprowadzenie testu t\n",
    "t_stat, p_val = stats.ttest_ind(sales_2015, sales_2010, alternative='greater')\n",
    "\n",
    "print(f'T-stat = {t_stat}, p-value= {p_val}')\n",
    "print(\"P-value jest > 0.05 nie odrzucamy hipotezy zerowej, więc że nie mamy wystarczających dowodów, aby stwierdzić że średnia sprzedaż była większa w 2015 niż w 2010 roku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72b38092",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 2230000,  2110000,  1420000,  1200000,  1160000,  1110000,\\n             1680000,  1630000, 82540000, 35520000,\\n            ...\\n               10000,    10000,    10000,    10000,    10000,    10000,\\n               10000,    10000,    10000,    10000],\\n           dtype='int64', length=6825)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Regresja liniowa dla 'Critic_Score' na 'Total_Sales'\u001B[39;00m\n\u001B[0;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m sm\u001B[38;5;241m.\u001B[39madd_constant(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCritic_Score\u001B[39m\u001B[38;5;124m'\u001B[39m])  \u001B[38;5;66;03m# dodanie stałej\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCritic_Score\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_sales\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m sm\u001B[38;5;241m.\u001B[39mOLS(y, X)\u001B[38;5;241m.\u001B[39mfit()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39msummary())\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1065\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[0;32m   1066\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_value(\u001B[38;5;241m*\u001B[39mkey, takeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_takeable)\n\u001B[1;32m-> 1067\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1069\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n\u001B[0;32m   1070\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1254\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;66;03m# ugly hack for GH #836\u001B[39;00m\n\u001B[0;32m   1253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multi_take_opportunity(tup):\n\u001B[1;32m-> 1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_multi_take\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1256\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1205\u001B[0m, in \u001B[0;36m_LocIndexer._multi_take\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;124;03mvalues: same type as the object being indexed\u001B[39;00m\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;66;03m# GH 836\u001B[39;00m\n\u001B[1;32m-> 1205\u001B[0m d \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1206\u001B[0m     axis: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_listlike_indexer(key, axis)\n\u001B[0;32m   1207\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (key, axis) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(tup, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_AXIS_ORDERS)\n\u001B[0;32m   1208\u001B[0m }\n\u001B[0;32m   1209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(d, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1206\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;124;03mvalues: same type as the object being indexed\u001B[39;00m\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;66;03m# GH 836\u001B[39;00m\n\u001B[0;32m   1205\u001B[0m d \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m-> 1206\u001B[0m     axis: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1207\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (key, axis) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(tup, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_AXIS_ORDERS)\n\u001B[0;32m   1208\u001B[0m }\n\u001B[0;32m   1209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(d, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1429\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1430\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1432\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[0;32m   6129\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Int64Index([ 2230000,  2110000,  1420000,  1200000,  1160000,  1110000,\\n             1680000,  1630000, 82540000, 35520000,\\n            ...\\n               10000,    10000,    10000,    10000,    10000,    10000,\\n               10000,    10000,    10000,    10000],\\n           dtype='int64', length=6825)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Regresja liniowa dla 'Critic_Score' na 'Total_Sales'\n",
    "X = sm.add_constant(df['Critic_Score'])  # dodanie stałej\n",
    "y = df.loc[df['Critic_Score'].index, total_sales]\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb83015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statystyka: 11.026800039682623, p-wartość: 3.730990653234972e-28\n",
      "p-value jest < 0.05 więc odrzucamy hipotezę, że średnie wartości ogólnej sprzedaży, a w Europie są statystycznie różne od siebie\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Czy średnie wartości sprzedaży w Ameryką Północną, a Europą są statystycznie różne od siebie?\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(df['NA_Sales'], df['EU_Sales'])\n",
    "print(f\"t-statystyka: {t_stat}, p-wartość: {p_val}\")\n",
    "print(\"p-value jest < 0.05 więc odrzucamy hipotezę, że średnie wartości ogólnej sprzedaży, a w Europie są statystycznie różne od siebie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8b8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=24.350, p=0.000\n",
      "Different distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "stat, p = ttest_rel(df['NA_Sales'], df['EU_Sales'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a287ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=0.000, p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Przeprowadź test Wilcoxona\n",
    "stat, p = wilcoxon(df[\"Critic_Score\"], df[\"User_Score\"])\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e67ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Shapiro-Wilka dla 'Critic_Score': ShapiroResult(statistic=0.9636805653572083, pvalue=2.761719651146815e-38)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Test Shapiro-Wilka na normalność dla krytycznych ocen gier\n",
    "shapiro_results = shapiro(df['Critic_Score'].dropna())\n",
    "print(f\"Test Shapiro-Wilka dla 'Critic_Score': {shapiro_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6174387d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
